# -*- coding: utf-8 -*-
"""DataMiningQ3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pctl2miqyDNVC7wAUwVe0NGCnSoRImSa
"""


# Import required libraries
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import re
from boruta import BorutaPy
from tqdm import tqdm

from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFECV
from sklearn.feature_selection import RFE

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz

import warnings
warnings.filterwarnings('ignore')
#st.set_option('deprecation.showPyplotGlobalUse', False)
# Read dataset
cases_state = pd.read_csv('./data_set/cases_state.csv')
tests_state = pd.read_csv('./data_set/tests_state.csv')
hospital = pd.read_csv('./data_set/hospital.csv')

st.set_page_config(page_title="BBC COVID-19 Analysis", page_icon="ğŸ“Š", layout='centered', initial_sidebar_state='auto')

"""# Group BBC Data Mining Assignment Question 3
"""

"""
# Description of the data
Among all the datasets provided by the Ministry of Health Malaysia, we decided to focus on three main datasets which are **cases_state**, **tests_state**, and **hospital**. This is because we are interested in the relationship between reported cases with the number of COVID-19 tests and hospital utilization.

Dataset **cases_state** records the daily COVID-19 cases at the state level, where the **tests_state** records the daily tests by type at the state level. The **hospital** dataset contains the data of the flow of patients to/out of hospitals. Example of the datasets are presented as follow:
"""

st.dataframe(cases_state.tail(5))
"""
Data Frame 1: cases_state.csv
"""

st.dataframe(tests_state.tail(5))
"""
Data Frame 2: tests_state.csv
"""

st.dataframe(hospital.tail(5))
"""
Data Frame 3: hospital.csv
"""

"""It is worth mentioning that the *cases_new* has included the *cases_import* for each day. For consistency, we capped the date for all 3 datasets at *2021-09-12*.

# Exploratory Data Analysis (EDA)
1. Checking for data types and missing values.

Data types for each column in the 3 datasets are examined as different data types required different manipulation techniques.
"""

# Checking for missing values
# In cases_state csv
dt_cases = cases_state.dtypes
nc_cases = cases_state.isna().sum()
null_sum = cases_state.isnull().sum().sum()
dt_df_cases = pd.DataFrame(dt_cases, columns=['Data Types'])
nc_df_cases = pd.DataFrame(nc_cases, columns=['No. of missing values'])

# In tests_state csv
dt_tests = tests_state.dtypes
nc_tests = tests_state.isna().sum()
dt_df_tests = pd.DataFrame(dt_tests, columns=['Data Types'])
nc_df_tests = pd.DataFrame(nc_tests, columns=['No. of missing values'])

# In hospital csv
dt_hospital = hospital.dtypes
nc_hospital = hospital.isna().sum()
dt_df_hospital = pd.DataFrame(dt_hospital, columns=['Data Types'])
nc_df_hospital = pd.DataFrame(nc_hospital, columns=['No. of missing values'])
data_cases = [["date","object"],["state","object"],
            ["cases_import","int64"],["cases_new","int64"],
            ["cases_recovered","int64"]]
data_cases = pd.DataFrame(data_cases, columns=['Columns','Data Types'])

data_tests = [["date","object"],["state","object"],
            ["rtk-ag","int64"],["pcr","int64"]]
data_tests = pd.DataFrame(data_tests, columns=['Columns','Data Types'])


data_hospital = [["date","object"],["state","object"],
            ["beds","int64"],["beds_covid","int64"],
            ["beds_noncrit","int64"],["admitted_pui","int64"],
            ["admitted_covid","int64"],["admitted_total","int64"],
            ["discharged_pui","int64"],["discharged_covid","int64"],
            ["discharged_total","int64"],["hosp_covid","int64"],
            ["hosp_pui","int64"],["hosp_noncovid","int64"]]
data_hospital = pd.DataFrame(data_hospital, columns=['Columns','Data Types'])


st.dataframe(data_cases)
"""
Data Frame 4: Variables' data types in cases_state.csv
"""

st.dataframe(data_tests)
"""
Data Frame 5: Variable's data types in tests_state.csv
"""

st.dataframe(data_hospital)
"""
Data Frame 6: Variables' data types in hospital.csv
"""

"""After that, any missing values, for example, NaN in numeric arrays, None or NaN in object arrays, NaT in datetimelike variables are detected in the datasets, and luckily 0 missing values are found."""

st.dataframe(nc_df_cases)
"""
Data Frame 7: Missing values in cases_state.csv
"""

st.dataframe(nc_df_tests)
"""
Data Frame 8: Missing values in tests_state.csv
"""

st.dataframe(nc_df_hospital)
"""
Data Frame 9: Missing values in hospital.csv
"""

"""
Moreover, the mean and median from the measurement of central tendency are extracted from the dataset to provides a brief understanding of the shape of the dataset. In this case, we are interested in 4 states which are **Pahang**, **Kedah**, **Johor**, and **Selangor**. The measurement of the central tendency is performed on the **cases_state** dataset which is considered as the label of our project findings. The mean and median of daily new cases for each state are shown in the data frame below:
"""
# Mesures of the central tendency
# Mean
states = ["Pahang","Kedah","Johor","Selangor"]
states_short = ["ph","kd","jh","sl"]

ph_daily = cases_state[cases_state['state'] == states[0]]
kd_daily = cases_state[cases_state['state'] == states[1]]
jh_daily = cases_state[cases_state['state'] == states[2]]
sl_daily = cases_state[cases_state['state'] == states[3]]

ph_mean = pd.DataFrame(ph_daily.mean(), columns=['Mean']).transpose()
kd_mean = pd.DataFrame(kd_daily.mean(), columns=['Mean']).transpose()
jh_mean = pd.DataFrame(jh_daily.mean(), columns=['Mean']).transpose()
sl_mean = pd.DataFrame(sl_daily.mean(), columns=['Mean']).transpose()

total_mean = pd.concat([ph_mean,kd_mean,jh_mean,sl_mean], ignore_index=True).set_index([states])
st.dataframe(total_mean)

"""
Data Frame 10: Mean values in cases_state.csv
"""

# Mesures of the central tendency
# Median
ph_median = pd.DataFrame(ph_daily.median(), columns=['Median']).transpose()
kd_median = pd.DataFrame(kd_daily.median(), columns=['Median']).transpose()
jh_median = pd.DataFrame(jh_daily.median(), columns=['Median']).transpose()
sl_median = pd.DataFrame(sl_daily.median(), columns=['Median']).transpose()

total_median = pd.concat([ph_median,kd_median,jh_median,sl_median], ignore_index=True).set_index([states])
st.dataframe(total_median)
"""
Data Frame 11: Median values in cases_state.csv
"""

"""To further visualize the data, a histogram is plotted to depict the shape of the data."""

# ph hist
# sns.set(rc={"figure.figsize":(30,12)})
# fig1, ax = plt.subplots()
# ax = sns.histplot(x="cases_new", data=ph_daily)
# plt.title("Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Pahang")
# st.pyplot(fig1)
st.image("./figure/1.png")

"""Figure 1: Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Pahang"""

# kd hist
# sns.set(rc={"figure.figsize":(30,12)})
# fig2, ax = plt.subplots()
# ax = sns.histplot(x="cases_new", data=kd_daily)
# plt.title("Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Kedah")
# st.pyplot(fig2)
st.image("./figure/2.png")

"""Figure 2: Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Kedah"""

# jh hist
# sns.set(rc={"figure.figsize":(30,12)})
# fig3, ax = plt.subplots()
# ax = sns.histplot(x="cases_new", data=jh_daily)
# plt.title("Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Johor")
# st.pyplot(fig3)
st.image("./figure/3.png")

"""Figure 3: Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Johor"""

# sl hist
# sns.set(rc={"figure.figsize":(30,12)})
# fig4, ax = plt.subplots()
# ax = sns.histplot(x="cases_new", data=sl_daily)
# plt.title("Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Selangor")
# st.pyplot(fig4)
st.image("./figure/4.png")

"""Figure 4: Histogram of Daily New Cases from 2020-01-25 to 2021-09-12 in Selangor

**Shape**: All 4 states have a similar shape for their histogram where the distributions are right-skewed. One of the reasons is that the daily cases are around 0 for a long period in the year 2020, but has increased drastically in 2021.

**Spreads**: Selangor has the widest spread where the minimum of new cases is located at 0 and reaches the peak at approximately 8500 cases.

**Outlier**: There are a few outliers detected from the histogram. For example, an outlier located at 800 in Pahang. The outliers in this dataset are not being removed as they might provide an interesting insight.

From the 4 histograms above, a question is formed to determine the starting point of the rising of new cases for a more accurate prediction.

**What is the month when the new cases started to rise in states Pahang, Kedah, Johor, and Selangor?**
"""

# ph line 11/20 - 1/21 
# sns.set(rc={"figure.figsize":(30,12)})
# fig5, ax = plt.subplots()
# ax = sns.lineplot(x="date", y="cases_new", data=ph_daily[(ph_daily['date']>="2020-11-01")&(ph_daily['date']<="2021-01-01")])
# plt.title("Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Pahang")
# plt.xticks(rotation=90)
# st.pyplot(fig5)
st.image("./figure/5.png")

"""Figure 5: Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Pahang"""

# kd line 11/20 - 1/21 
# sns.set(rc={"figure.figsize":(30,12)})
# fig6, ax = plt.subplots()
# ax = sns.lineplot(x="date", y="cases_new", data=kd_daily[(kd_daily['date']>="2020-11-01")&(kd_daily['date']<="2021-01-01")])
# plt.title("Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Kedah")
# plt.xticks(rotation=90)
# st.pyplot(fig6)
st.image("./figure/6.png")

"""Figure 6: Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Kedah"""

# jh line 11/20 - 1/21 
# sns.set(rc={"figure.figsize":(30,12)})
# fig7, ax = plt.subplots()
# ax = sns.lineplot(x="date", y="cases_new", data=jh_daily[(jh_daily['date']>="2020-11-01")&(jh_daily['date']<="2021-01-01")])
# plt.title("Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Johor")
# plt.xticks(rotation=90)
# st.pyplot(fig7)
st.image("./figure/7.png")

"""Figure 7: Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Johor"""

# sl line 11/20 - 1/21 
# sns.set(rc={"figure.figsize":(30,12)})
# fig8, ax = plt.subplots()
# ax = sns.lineplot(x="date", y="cases_new", data=sl_daily[(sl_daily['date']>="2020-11-01")&(sl_daily['date']<="2021-01-01")])
# plt.title("Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Selangor")
# plt.xticks(rotation=90)
# st.pyplot(fig8)
st.image("./figure/8.png")


"""Figure 8: Line graph of Daily New Cases from 2020-11-01 to 2021-01-01 in Selangor

**From the 4 line graph above, it can be concluded that the number of daily new cases started to rise around mid-November 2020**. 

# Correlation Analysis

In this section, we opt to discover the correlation of Pahang and Johor with other states. In other words, **what are the states that exhibit a strong correlation with (i)Pahang, and (ii)Johor**? Daily new cases are chosen as the interest of the correlation analysis.

A new data frame is prepared where daily new cases for each state are extracted and merged into a new data frame to have 16 *states* in columns and *cases_new* as rows. Unused columns from the original data frame which is ['state', 'cases_import', 'cases_recovered'] are dropped. The final data frame as shown below is used for correlation analysis.
"""

state = [] 
state_name = ['Johor','Pahang','Pulau Pinang','Kedah','Kelantan','Melaka',
              'Negeri Sembilan','Perak','Perlis','Sabah','Sarawak','Selangor',
              'Terengganu','W.P. Labuan','W.P. Kuala Lumpur','W.P. Putrajaya']

for i in range(16):
  state.append(cases_state.loc[cases_state['state'] == state_name[i]])
  state[i] = state[i].drop(['state','cases_import','cases_recovered'], axis=1)
  state[i] = state[i].rename(columns={'cases_new': 'Cases_New_' + state_name[i]})

result = state[0]
for i in range (15):
  result = result.merge(state[i+1], on='date')

st.dataframe(result.head(5))

"""
Data Frame 12: The new data frame that have been created to perform correlation analysis

After that, correlation analysis is done and the scores are presented in the following data frame.
"""

corrM = result.corr()
st.dataframe(corrM.head(2))

"""
Data Frame 13: Correlation table for Johor and Pahang with other states

From the table above, it can be noticed that several states are strongly correlated with Johor which are Penang, Perak, and Terengganu because their correlation score is close to 1 which indicates that they are strongly correlated with Johor in terms of new daily cases.

On the other hand, we can see that Kedah, Perak, and Terengganu are strongly correlated with Pahang as their correlation score with Pahang state is close to 1 as well. An illustration of the correlation is shown in Figure 9.
"""

# fig11, ax = plt.subplots()
# sns.heatmap(corrM.head(2))
# st.pyplot(fig11)
st.image("./figure/9.png")

"""Figure 9: The correlation matrix of Johor and Pahang with other states

# Feature Selection

Feature selection is carried out before training the model to ensure the quality of the feature.  **Boruta** and **Recursive Feature Elimination (RFE)** is chosen as the feature selection methods.

*cases_state, test_state, and hospital* data are selected as we believe these data are helpful for the cases prediction. The selected data are merged to obtain a new data frame for each state. The example of the data frame for Pahang is shown below.
"""

def ranking(ranks, names, order=1):
    minmax = MinMaxScaler()
    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]
    ranks = map(lambda x: round(x,2), ranks)
    return dict(zip(names, ranks))

rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=2)
feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)

#refer to lab7  
test = []
test_states = []
hospitals = []
hospital_states = []
merge = []
test_state_name = ['Pahang','Kedah','Johor','Selangor']

for i in range(4):
  test_states.append(cases_state.loc[cases_state['state'] == test_state_name[i]])
  test_states[i] = test_states[i].drop(['state','cases_recovered'], axis=1)
  test_states[i] = test_states[i].rename(columns={'cases_new': 'Cases_New_' + test_state_name[i], 'cases_import' : 'Cases_Import_' + test_state_name[i]})

for i in range(4):
  test.append(tests_state.loc[tests_state['state'] == test_state_name[i]])
  test[i] = test[i].drop(['state'], axis=1)
  test[i] = test[i].rename(columns={'rtk-ag': 'RTk_test_' + test_state_name[i], 'pcr' : 'PCR_' + test_state_name[i]})

for i in range(4):
  hospitals.append(hospital.loc[hospital['state'] == test_state_name[i]])
  hospitals[i] = hospitals[i].drop(['state'], axis=1)
  hospitals[i] = hospitals[i].rename(columns={'beds': 'beds_' + test_state_name[i], 'beds_covid' : 'beds_covid_' + test_state_name[i]})

for i in range(4):
  merge.append(test[i].merge(hospitals[i], on='date'))

for i in range(4):
  merge[i] = merge[i].merge(test_states[i], on='date')
  
st.dataframe(merge[0].head(5))

"""
Data Frame 14: The data frame of Pahang prepared for feature selection

A total of 15 features are to be evaluated to predict the daily new cases for each state. The 15 features will be fed into Boruta and RFE feature selector and the best 5 features will be chosen base on their score. The features are then used in our predictive model to predict the daily cases of the states.

Before the data can be used as the input of the feature selector, the data frames are split into features(x) and labels(y). In our case, there will be 15 features from *tests_state* and *hospital* and 1 label *cases_new*. Moreover, unused columns such as *date* are dropped from the data frames.
"""

#Pahang boruta feature score
y_pahang = merge[0].Cases_New_Pahang
X_pahang = merge[0].drop(['date','Cases_New_Pahang'], axis=1)
# colnames = X_pahang.columns

# feat_selector.fit(X_pahang.values,y_pahang.values)

# boruta_score_pahang = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)
# boruta_score_pahang = pd.DataFrame(list(boruta_score_pahang.items()), columns=['Features','Score'])
# boruta_score_pahang = boruta_score_pahang.sort_values("Score", ascending=False)

st.dataframe(pd.DataFrame(X_pahang).head(5))
"""
Data Frame 15: Example of features(x) for Pahang
"""

st.dataframe(pd.DataFrame(y_pahang).head(5))
"""
Data Frame 16: Example of label(y) for Pahang
"""

# fig13, ax = plt.subplots()
# fig13 = sns.catplot(x="Score", y="Features", data=boruta_score_pahang[0:10], kind="bar", 
#               height=14, aspect=1.9, palette="coolwarm")
# plt.title("Pahang Boruta Top 10 Features")
# st.pyplot(fig13)
st.image("./figure/10.png")
"""Figure 10: The top 10 features of Pahang state selected by Boruta. """

#Kedah boruta score
y_kedah = merge[1].Cases_New_Kedah
X_kedah = merge[1].drop(['date','Cases_New_Kedah'], axis=1)
# colnames = X_kedah.columns

# feat_selector.fit(X_kedah.values,y_kedah.values)

# boruta_score_kedah = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)
# boruta_score_kedah = pd.DataFrame(list(boruta_score_kedah.items()), columns=['Features','Score'])
# boruta_score_kedah = boruta_score_kedah.sort_values("Score", ascending=False)

# fig14, ax = plt.subplots()
# fig14 = sns.catplot(x="Score", y="Features", data=boruta_score_kedah[0:10], kind="bar", 
#               height=14, aspect=1.9, palette="coolwarm")
# plt.title("Kedah Boruta Top 10 Features")
# st.pyplot(fig14)
st.image("./figure/11.png")
"""Figure 11: The top 10 features of Kedah state selected by Boruta"""

#Johor Boruta Score
y_johor = merge[2].Cases_New_Johor
X_johor = merge[2].drop(['date','Cases_New_Johor'], axis=1)
# colnames = X_johor.columns

# feat_selector.fit(X_johor.values,y_johor.values)
# boruta_score_johor = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)
# boruta_score_johor = pd.DataFrame(list(boruta_score_johor.items()), columns=['Features','Score'])
# boruta_score_johor = boruta_score_johor.sort_values("Score", ascending=False)

# fig15, ax = plt.subplots()
# fig15 = sns.catplot(x="Score", y="Features", data=boruta_score_johor[0:10], kind="bar", 
#               height=14, aspect=1.9, palette="coolwarm")
# plt.title("Johor Boruta Top 10 Features")
# st.pyplot(fig15)
st.image("./figure/12.png")
"""Figure 12: The top 10 features of Johor state selected by Boruta."""

#Selangor Boruta Score
y_selangor = merge[3].Cases_New_Selangor
X_selangor = merge[3].drop(['date','Cases_New_Selangor'], axis=1)
# colnames = X_selangor.columns

# feat_selector.fit(X_selangor.values,y_selangor.values)
# boruta_score_selangor = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)
# boruta_score_selangor = pd.DataFrame(list(boruta_score_selangor.items()), columns=['Features','Score'])
# boruta_score_selangor = boruta_score_selangor.sort_values("Score", ascending=False)

# fig16, ax = plt.subplots()
# fig16 = sns.catplot(x="Score", y="Features", data=boruta_score_selangor[0:10], kind="bar", height=14, aspect=1.9, palette="coolwarm")
# plt.title("Selangor Boruta Top 10 Features")
# st.pyplot(fig16)
st.image("./figure/13.png")
"""Figure 13: The top 10 features of Selangor state selected by Boruta."""

#Pahang RFE Score
# rfe = RFECV(rf, min_features_to_select=1, cv=2)
# rfe.fit(X_pahang.values, y_pahang.values)
# colnames = X_pahang.columns

# pahang_rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)
# pahang_rfe_score = pd.DataFrame(list(pahang_rfe_score.items()), columns=['Features','Score'])
# pahang_rfe_score = pahang_rfe_score.sort_values("Score", ascending=False)

# fig17, ax = plt.subplots()
# fig17= sns.catplot(x="Score", y="Features", data=pahang_rfe_score[0:10], kind="bar", 
#                height=14, aspect=1.9, palette="coolwarm")
# plt.title("Pahang RFE Top 10 Features")
# st.pyplot(fig17)
st.image("./figure/14.png")
"""Figure 14: The top 10 features of Pahang state selected by RFE."""

#Kedah RFE Score
# rfe.fit(X_kedah.values, y_kedah.values)
# colnames = X_kedah.columns

# kedah_rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)
# kedah_rfe_score = pd.DataFrame(list(kedah_rfe_score.items()), columns=['Features','Score'])
# kedah_rfe_score = kedah_rfe_score.sort_values("Score", ascending=False)

# fig18, ax = plt.subplots()
# fig18 = sns.catplot(x="Score", y="Features", data=kedah_rfe_score[0:10], kind="bar", 
#                height=14, aspect=1.9, palette="coolwarm")
# plt.title("Kedah RFE Top 10 Features")
# st.pyplot(fig18)
st.image("./figure/15.png")
"""Figure 15: The top 10 features of Kedah state selected by RFE."""

#Johor RFE Score
# rfe.fit(X_johor.values, y_johor.values)
colnames = X_johor.columns

# johor_rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)
# johor_rfe_score = pd.DataFrame(list(johor_rfe_score.items()), columns=['Features','Score'])
# johor_rfe_score = johor_rfe_score.sort_values("Score", ascending=False)

# fig19, ax = plt.subplots()
# fig19 = sns.catplot(x="Score", y="Features", data=johor_rfe_score[0:10], kind="bar", 
#                height=14, aspect=1.9, palette="coolwarm")
# plt.title("Johor RFE Top 10 Features")
# st.pyplot(fig19)
st.image("./figure/16.png")
"""Figure 16: The top 10 features of Johor state selected by RFE.

# Predictive Modelling

After performing feature selection on the data, few features have been selected by their performance. We will select the features that have a high score in both the Boruta and RFE methods to fit into our predictive model for each state to increase the accuracy and reduce the training time of the model.
"""

# Preparing data for Pahang
y_pahang_change = y_pahang.copy()
for i in range(1, len(y_pahang_change)):
  if(y_pahang_change[i] < y_pahang[i-1]):
      y_pahang_change[i] = 0
  else:
      y_pahang_change[i] = 1

y_pahang_change[0] = y_pahang_change[1]

# merged_rank_ph =  boruta_score_pahang[0:10].join(pahang_rfe_score[0:10], lsuffix="Boruta", rsuffix="RFE")
# merged_rank_ph['Total'] = merged_rank_ph['ScoreBoruta'] + merged_rank_ph['ScoreRFE']

#X_pahang_top5 = X_pahang[['hosp_pui','RTk_test_Pahang','admitted_total','discharged_pui','discharged_covid']]
X_pahang_top5 = X_pahang[['PCR_Pahang','RTk_test_Pahang','hosp_covid','discharged_covid','discharged_total']]
X_train_pahang, X_test_pahang, y_train_pahang, y_test_pahang = train_test_split(X_pahang_top5, y_pahang_change, test_size=0.30, random_state=0)
X_train_pahang_reg, X_test_pahang_reg, y_train_pahang_reg, y_test_pahang_reg = train_test_split(X_pahang_top5, y_pahang, test_size=0.30, random_state=0)

st.image("./figure/17.png")
"""
Figure 17: Top 5 features of Pahang State

The figure above shows the top 5 features chosen for Pahang state based on Boruta and RFE score to fit in our model later which were *RTk_test_Pahang, PCR_Pahang, discharged_covid, hasp_covid, discharged_total*.
"""

# Preparing data for Kedah
y_kedah_change = y_kedah.copy()
for i in range(1, len(y_kedah_change)):
  if(y_kedah_change[i] < y_kedah[i-1]):
      y_kedah_change[i] = 0
  else:
      y_kedah_change[i] = 1

y_kedah_change[0] = y_kedah_change[1]

# merged_rank_kd =  boruta_score_kedah[0:10].join(kedah_rfe_score[0:10], lsuffix="Boruta", rsuffix="RFE")
# merged_rank_kd['Total'] = merged_rank_kd['ScoreBoruta'] + merged_rank_kd['ScoreRFE']

#X_kedah_top5 = X_kedah[['hosp_covid','RTk_test_Kedah','PCR_Kedah','discharged_total','admitted_total']]
X_kedah_top5 = X_kedah[['PCR_Kedah','RTk_test_Kedah','admitted_covid','admitted_total','discharged_covid']]
X_train_kedah, X_test_kedah, y_train_kedah, y_test_kedah = train_test_split(X_kedah_top5, y_kedah_change, test_size=0.30, random_state=0)
X_train_kedah_reg, X_test_kedah_reg, y_train_kedah_reg, y_test_kedah_reg = train_test_split(X_kedah_top5, y_kedah, test_size=0.30, random_state=0)

st.image("./figure/18.png")
"""
Figure 18: Top 5 features of Kedah State

The figure above shows the top 5 features chosen for Kedah state based on Boruta and RFE score to fit in our model later which were *PCR_Kedah, RTk_test_Kedah, admitted_covid, admitted_total, discharged_covid.*
"""

# Preparing data for Johor
y_johor_change = y_johor.copy()
for i in range(1, len(y_johor_change)):
  if(y_johor_change[i] < y_johor[i-1]):
      y_johor_change[i] = 0
  else:
      y_johor_change[i] = 1

y_johor_change[0] = y_johor_change[1]

# merged_rank_jh =  boruta_score_johor[0:10].join(johor_rfe_score[0:10], lsuffix="Boruta", rsuffix="RFE")
# merged_rank_jh['Total'] = merged_rank_jh['ScoreBoruta'] + merged_rank_jh['ScoreRFE']

#X_johor_top5 = X_johor[['RTk_test_Johor','admitted_pui','hosp_covid','hosp_noncovid','admitted_total']]
X_johor_top5 = X_johor[['admitted_pui', 'hosp_pui', 'discharged_total', 'discharged_covid', 'PCR_Johor']]

X_train_johor, X_test_johor, y_train_johor, y_test_johor = train_test_split(X_johor_top5, y_johor_change, test_size=0.30, random_state=0)
X_train_johor_reg, X_test_johor_reg, y_train_johor_reg, y_test_johor_reg = train_test_split(X_johor_top5, y_johor, test_size=0.30, random_state=0)

st.image("./figure/19.png")
"""
Figure 19: Top 5 features of Johor State

The figure above shows the top 5 features chosen for Johor state based on Boruta and RFE score to fit in our model later which were *admitted_pui, hosp_pui, discharged_total, discharged_covid, PCR_Johor.*
"""

# Preparing data for Selangor
y_selangor_change = y_selangor.copy()
for i in range(1, len(y_selangor_change)):
  if(y_selangor_change[i] < y_selangor[i-1]):
      y_selangor_change[i] = 0
  else:
      y_selangor_change[i] = 1

y_selangor_change[0] = y_selangor_change[1]

# merged_rank_sl =  boruta_score_selangor[0:10]

X_selangor_top5 = X_selangor[['RTk_test_Selangor', 'PCR_Selangor', 'admitted_covid', 'admitted_total', 'discharged_pui']]
X_train_selangor, X_test_selangor, y_train_selangor, y_test_selangor = train_test_split(X_selangor_top5, y_selangor_change, test_size=0.30, random_state=0)
X_train_selangor_reg, X_test_selangor_reg, y_train_selangor_reg, y_test_selangor_reg = train_test_split(X_selangor_top5, y_selangor, test_size=0.30, random_state=0)

st.image("./figure/20.png")

"""
Figure 20: Top 5 features of Selangor State

The figure above shows the top 5 features chosen for Selangor state based on Boruta score to fit in our model later which were *RTk_test_Selangor, PCR_Selangor, admitted_covid, admitted_total, discharged_pui.*
"""
st.info("NOTE: Due to Selangor state data is unable to fit into RFE, the top 5 features for Selangor is chosen based on Boruta score only")

"""
# Regression
The regression is done to determine the strength of the relationship between selected features and the daily new cases. Two regression models used for the cases prediction are:

1. **Multiple Linear Regression**
2. **Decision Tree Regression**

### Multiple Linear Regression
"""
"""
Multiple linear regression (MLR), also simply known as multiple regression, is a statistical technique that uses several explanatory variables to predict the outcome of a response variable.
"""

# Pahang
mlr_pahang = LinearRegression().fit(X_train_pahang_reg, y_train_pahang_reg)
mlr_pred_pahang = mlr_pahang.predict(X_test_pahang_reg)

mlr_reg_mse_ph = metrics.mean_squared_error(y_test_pahang_reg, mlr_pred_pahang)
mlr_reg_mae_ph = metrics.mean_absolute_error(y_test_pahang_reg, mlr_pred_pahang)
mlr_reg_r2_ph = metrics.r2_score(y_test_pahang_reg, mlr_pred_pahang)

# Kedah
mlr_kedah = LinearRegression().fit(X_train_kedah_reg, y_train_kedah_reg)
mlr_pred_kedah = mlr_kedah.predict(X_test_kedah_reg)

mlr_reg_mse_kd = metrics.mean_squared_error(y_test_kedah_reg, mlr_pred_kedah)
mlr_reg_mae_kd = metrics.mean_absolute_error(y_test_kedah_reg, mlr_pred_kedah)
mlr_reg_r2_kd = metrics.r2_score(y_test_kedah_reg, mlr_pred_kedah)

# Johor
mlr_johor = LinearRegression().fit(X_train_johor_reg, y_train_johor_reg)
mlr_pred_johor = mlr_johor.predict(X_test_johor_reg)

mlr_reg_mse_jh = metrics.mean_squared_error(y_test_johor_reg, mlr_pred_johor)
mlr_reg_mae_jh = metrics.mean_absolute_error(y_test_johor_reg, mlr_pred_johor)
mlr_reg_r2_jh = metrics.r2_score(y_test_johor_reg, mlr_pred_johor)

# Selangor
mlr_selangor = LinearRegression().fit(X_train_selangor_reg, y_train_selangor_reg)
mlr_pred_selangor = mlr_selangor.predict(X_test_selangor_reg)

mlr_reg_mse_sl = metrics.mean_squared_error(y_test_selangor_reg, mlr_pred_selangor)
mlr_reg_mae_sl = metrics.mean_absolute_error(y_test_selangor_reg, mlr_pred_selangor)
mlr_reg_r2_sl = metrics.r2_score(y_test_selangor_reg, mlr_pred_selangor)

"""Multiple Linear Regression performace comparision for each state"""

states = [["Pahang", "Kedah", "Johor","Selangor"]]
data = {"Mean squared error":[mlr_reg_mse_ph, mlr_reg_mse_kd, mlr_reg_mse_jh, mlr_reg_mse_sl],
        "Mean absolute error":[mlr_reg_mae_ph, mlr_reg_mae_kd, mlr_reg_mae_jh, mlr_reg_mae_sl],
        "R^2 score":[mlr_reg_r2_ph, mlr_reg_r2_kd, mlr_reg_r2_jh,mlr_reg_r2_sl]}
mlp_reg_score = pd.DataFrame(data, index = states)
st.dataframe(mlp_reg_score)
"""
Data Frame 17: Data frame of the performance score for MLR
"""

"""### Decision Tree Regression"""

# Decision Tree Regression
"""
Decision trees are prediction models that determine a goal value using a collection of binary rules. A sine curve with additional noisy observations is fitted using decision trees. It learns local linear regressions that approximate the sine curve as an outcome.
"""
# Pahang
dt_reg_p = DecisionTreeRegressor(max_depth=5)
dt_reg_pahang = dt_reg_p.fit(X_train_pahang_reg, y_train_pahang_reg)
dt_reg_pred_pahang = dt_reg_pahang.predict(X_test_pahang_reg)

dt_reg_mse_ph = metrics.mean_squared_error(y_test_pahang_reg, dt_reg_pred_pahang)
dt_reg_mae_ph = metrics.mean_absolute_error(y_test_pahang_reg, dt_reg_pred_pahang)
dt_reg_r2_ph = metrics.r2_score(y_test_pahang_reg, dt_reg_pred_pahang)


# Kedah
dt_reg_k = DecisionTreeRegressor(max_depth=5)
dt_reg_kedah = dt_reg_k.fit(X_train_kedah_reg, y_train_kedah_reg)
dt_reg_pred_kedah = dt_reg_kedah.predict(X_test_kedah_reg)

dt_reg_mse_kd = metrics.mean_squared_error(y_test_kedah_reg, dt_reg_pred_kedah)
dt_reg_mae_kd = metrics.mean_absolute_error(y_test_kedah_reg, dt_reg_pred_kedah)
dt_reg_r2_kd = metrics.r2_score(y_test_kedah_reg, dt_reg_pred_kedah)


# Johor
dt_reg_j = DecisionTreeRegressor(max_depth=5)
dt_reg_johor = dt_reg_j.fit(X_train_johor_reg, y_train_johor_reg)
dt_reg_pred_johor = dt_reg_johor.predict(X_test_johor_reg)

dt_reg_mse_jh = metrics.mean_squared_error(y_test_johor_reg, dt_reg_pred_johor)
dt_reg_mae_jh = metrics.mean_absolute_error(y_test_johor_reg, dt_reg_pred_johor)
dt_reg_r2_jh = metrics.r2_score(y_test_johor_reg, dt_reg_pred_johor)


# Selangor
dt_reg_sl = DecisionTreeRegressor(max_depth=5)
dt_reg_selangor = dt_reg_p.fit(X_train_selangor_reg, y_train_selangor_reg)
dt_reg_pred_selangor = dt_reg_selangor.predict(X_test_selangor_reg)

dt_reg_mse_sl = metrics.mean_squared_error(y_test_selangor_reg, dt_reg_pred_selangor)
dt_reg_mae_sl = metrics.mean_absolute_error(y_test_selangor_reg, dt_reg_pred_selangor)
dt_reg_r2_sl = metrics.r2_score(y_test_selangor_reg, dt_reg_pred_selangor)

"""Decision tree regression performace comparision for each state"""

states = [["Pahang", "Kedah", "Johor","Selangor"]]
data = {"Mean squared error":[dt_reg_mse_ph, dt_reg_mse_kd, dt_reg_mse_jh, dt_reg_mse_sl],
        "Mean absolute error":[dt_reg_mae_ph, dt_reg_mae_kd, dt_reg_mae_jh, dt_reg_mae_sl],
        "R^2 score":[dt_reg_r2_ph, dt_reg_r2_kd, dt_reg_r2_jh,dt_reg_r2_sl]}
dt_reg_score = pd.DataFrame(data, index=states)
st.dataframe(dt_reg_score)

"""
Data Frame 18: Data frame of the performance score for DTR

Based on the 2 data frames above, it can be concluded that MLP performs better in predicting the number of daily new cases, especially on Johor. Both regression models are not performing well for Selangor data and one of the possible reasons is the presence of outliers where mean squared error and mean absolute error are sensitive to it.
"""

"""
# Classification

Classification is done to predict the increasing(1) or decreasing(0) of the daily cases. Two of the classification models have been used which are:

1. **Logistic Regression**
2. **Desicion Tree Classification**

### Logistic Regression
"""
st.info("The top left of the confusion matrix indicates True Negative (Actual label is 0 and Predicted label is 0), the top right of the confusion matrix indicates False Positive (Actual label is 0 and Predicted label is 1), the bottom left of the confusion matrix indicates False Negative (Actual label is 1 and Predicted label is 0), the bottom right of the confusion matrix indicates True Positive (Actual label is 1 and predicted label is 1). Hence, the top left and bottom right of the confusion matrix represent correct predictions whereas the top right and bottom left of the confusion matrix represent wrong predictions.")

# Pahang Logistic Regression
log_reg_p = LogisticRegression()
log_reg_pahang = log_reg_p.fit(X_train_pahang, y_train_pahang)
log_reg_pred_pahang = log_reg_pahang.predict(X_test_pahang)

cnf_matrix_pahang = metrics.confusion_matrix(y_test_pahang, log_reg_pred_pahang)
class_names = [0,1] # name  of classes
fig20, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

log_pahang_accuracy = metrics.accuracy_score(y_test_pahang, log_reg_pred_pahang)
log_pahang_precision = metrics.precision_score(y_test_pahang, log_reg_pred_pahang)
log_pahang_recall = metrics.recall_score(y_test_pahang, log_reg_pred_pahang)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_pahang), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Pahang', y=1.1)
plt.ylabel('Actual label Pahang')
plt.xlabel('Predicted label Pahang')
st.pyplot(fig20)
"""Figure 21: Confusion Matrix for Pahang State using Logistic Regression """

# Kedah Logistic Regression
log_reg_k = LogisticRegression()
log_reg_kedah = log_reg_k.fit(X_train_kedah, y_train_kedah)
log_reg_pred_kedah = log_reg_kedah.predict(X_test_kedah)

cnf_matrix_kedah = metrics.confusion_matrix(y_test_kedah, log_reg_pred_kedah)
class_names = [0,1] # name  of classes
fig21, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

log_kedah_accuracy = metrics.accuracy_score(y_test_kedah, log_reg_pred_kedah)
log_kedah_precision = metrics.precision_score(y_test_kedah, log_reg_pred_kedah)
log_kedah_recall = metrics.recall_score(y_test_kedah, log_reg_pred_kedah)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_kedah), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Kedah', y=1.1)
plt.ylabel('Actual label Kedah')
plt.xlabel('Predicted label Kedah')
st.pyplot(fig21)
"""Figure 22: Confusion Matrix for Kedah State using Logistic Regression """

# Johor Logistic Regression
log_reg_j = LogisticRegression()
log_reg_johor = log_reg_j.fit(X_train_johor, y_train_johor)
log_reg_pred_johor = log_reg_johor.predict(X_test_johor)

cnf_matrix_johor = metrics.confusion_matrix(y_test_johor, log_reg_pred_johor)
class_names = [0,1] # name of classes
fig22, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

log_johor_accuracy = metrics.accuracy_score(y_test_johor, log_reg_pred_johor)
log_johor_precision = metrics.precision_score(y_test_johor, log_reg_pred_johor)
log_johor_recall = metrics.recall_score(y_test_johor, log_reg_pred_johor)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_johor), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Johor', y=1.1)
plt.ylabel('Actual label Johor')
plt.xlabel('Predicted label Johor')
st.pyplot(fig22)

"""Figure 23: Confusion Matrix for Johor State using Logistic Regression """

# Selangor Logistic Regression
log_reg_p = LogisticRegression()
log_reg_selangor = log_reg_p.fit(X_train_selangor, y_train_selangor)
log_reg_pred_selangor = log_reg_selangor.predict(X_test_selangor)

cnf_matrix_selangor = metrics.confusion_matrix(y_test_selangor, log_reg_pred_selangor)
class_names = [0,1] # name  of classes
fig23, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

log_selangor_accuracy = metrics.accuracy_score(y_test_selangor, log_reg_pred_selangor)
log_selangor_precision = metrics.precision_score(y_test_selangor, log_reg_pred_selangor)
log_selangor_recall = metrics.recall_score(y_test_selangor, log_reg_pred_selangor)
#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_selangor), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Selangor', y=1.1)
plt.ylabel('Actual label Selangor')
plt.xlabel('Predicted label Selangor')
st.pyplot(fig23)
"""Figure 24: Confusion Matrix for Selangor State using Logistic Regression"""

states = [["Pahang", "Kedah", "Johor","Selangor"]]
data = {"Accuracy":[log_pahang_accuracy, log_kedah_accuracy, log_johor_accuracy, log_selangor_accuracy],
        "Precision":[log_pahang_precision, log_kedah_precision, log_johor_precision, log_selangor_precision],
        "Recall score":[log_pahang_recall, log_kedah_recall, log_johor_recall, log_selangor_recall]}
log_reg_score = pd.DataFrame(data, index=states)
st.dataframe(log_reg_score)

"""Data Frame 19: Logistic Regression performace comparision for each state"""

"""The data frame shows the performance of logistic regression on predicting increasing or decreasing cases for each state."""

""" ### Decision Tree Classification """
st.info("The top left of the confusion matrix indicates True Negative(Actual label is 0 and Predicted label is 0), the top right of the confusion matrix indicates False Positive(Actual label is 0 and Predicted label is 1),  the bottom left of the confusion matrix indicates False Negative(Actual label is 1 and Predicted label is 0), the bottom right of the confusion matrix indicates True Positive(Actual label is 1 and predicted label is 1). Hence, the top left and bottom right of the confusion matrix represent correct predictions whereas the top right and bottom left of the confusion matrix represent wrong predictions")

#Pahang Classifier
clf_pahang = DecisionTreeClassifier(criterion="entropy", max_depth=5)
clf_pahang = clf_pahang.fit(X_train_pahang,y_train_pahang)
clf_y_pred_pahang = clf_pahang.predict(X_test_pahang)

cnf_matrix_pahang_dt = metrics.confusion_matrix(y_test_pahang, clf_y_pred_pahang)
class_names = [0,1] # name  of classes
fig24, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

dc_pahang_accuracy = metrics.accuracy_score(y_test_pahang, clf_y_pred_pahang)
dc_pahang_precision = metrics.precision_score(y_test_pahang, clf_y_pred_pahang)
dc_pahang_recall = metrics.recall_score(y_test_pahang, clf_y_pred_pahang)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_pahang_dt), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Pahang', y=1.1)
plt.ylabel('Actual label Pahang')
plt.xlabel('Predicted label Pahang')
st.pyplot(fig24)

"""Figure 25: Confusion Matrix for Pahang State using Decision Tree Classification """

#Kedah Classifier
clf_kedah = DecisionTreeClassifier(criterion="entropy", max_depth=5)
clf_kedah = clf_kedah.fit(X_train_kedah,y_train_kedah)
clf_y_pred_kedah = clf_kedah.predict(X_test_kedah)

cnf_matrix_kedah_dt = metrics.confusion_matrix(y_test_kedah, clf_y_pred_kedah)
class_names = [0,1] # name  of classes
fig25, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

dc_kedah_accuracy = metrics.accuracy_score(y_test_kedah, clf_y_pred_kedah)
dc_kedah_precision = metrics.precision_score(y_test_kedah, clf_y_pred_kedah)
dc_kedah_recall = metrics.recall_score(y_test_kedah, clf_y_pred_kedah)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_kedah_dt), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Kedah', y=1.1)
plt.ylabel('Actual label Kedah')
plt.xlabel('Predicted label Kedah')
st.pyplot(fig25)

"""Figure 26: Confusion Matrix for Kedah State using Decision Tree Classification """

#Johor Classifier
clf_johor = DecisionTreeClassifier(criterion="entropy", max_depth=5)
clf_johor = clf_johor.fit(X_train_johor, y_train_johor)
clf_y_pred_johor = clf_johor.predict(X_test_johor)

cnf_matrix_johor_dt = metrics.confusion_matrix(y_test_johor, clf_y_pred_johor)
class_names = [0,1] # name  of classes
fig26, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

dc_johor_accuracy = metrics.accuracy_score(y_test_johor, clf_y_pred_johor)
dc_johor_precision = metrics.precision_score(y_test_johor, clf_y_pred_johor)
dc_johor_recall = metrics.recall_score(y_test_johor, clf_y_pred_johor)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_johor_dt), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Johor', y=1.1)
plt.ylabel('Actual label Johor')
plt.xlabel('Predicted label Johor')
st.pyplot(fig26)

"""Figure 27: Confusion Matrix for Johor State using Decision Tree Classification """

#Selangor Classifier
clf_selangor = DecisionTreeClassifier(criterion="entropy", max_depth=5)
clf_selangor = clf_selangor.fit(X_train_selangor,y_train_selangor)
clf_y_pred_selangor = clf_selangor.predict(X_test_selangor)

cnf_matrix_selangor_dt = metrics.confusion_matrix(y_test_selangor, clf_y_pred_selangor)
class_names = [0,1] # name  of classes
fig27, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)


dc_selangor_accuracy = metrics.accuracy_score(y_test_selangor, clf_y_pred_selangor)
dc_selangor_precision = metrics.precision_score(y_test_selangor, clf_y_pred_selangor)
dc_selangor_recall = metrics.recall_score(y_test_selangor, clf_y_pred_selangor)

#create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_selangor_dt), annot=True, cmap="YlGnBu", fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix Selangor', y=1.1)
plt.ylabel('Actual label Selangor')
plt.xlabel('Predicted label Selangor')
st.pyplot(fig27)

"""Figure 28: Confusion Matrix for Selangor State using Decision Tree Classification """

states = [["Pahang", "Kedah", "Johor","Selangor"]]
data = {"Accuracy":[dc_pahang_accuracy, dc_kedah_accuracy, dc_johor_accuracy, dc_selangor_accuracy],
        "Precision":[dc_pahang_precision, dc_kedah_precision, dc_johor_precision, dc_selangor_precision],
        "Recall score":[dc_pahang_recall, dc_kedah_recall, dc_johor_recall, dc_selangor_recall]}
dc_score = pd.DataFrame(data, index=states)
st.dataframe(dc_score)

"""
Data Frame 20: Decision Tree Classification performace comparision for each state

The data frame shows the performance of decision tree classification on predicting increasing or decreasing cases for each state.

Overall, among the 2 classification models, decision tree classification is a better model in predicting increases or decreases of daily cases because the overall accuracy, precision and recall score for each state is higher than logistic regression.
"""